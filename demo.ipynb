{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TopicGPT_Python package\n",
    "\n",
    "`topicgpt_python` consists of five modules in total: \n",
    "- `generate_topic_lvl1` generates high-level and generalizable topics. \n",
    "- `generate_topic_lvl2` generates low-level and specific topics to each high-level topic.\n",
    "- `refine_topics` refines the generated topics by merging similar topics and removing irrelevant topics.\n",
    "- `assign_topics` assigns the generated topics to the input text, along with a quote that supports the assignment.\n",
    "- `correct_topics` corrects the generated topics by reprompting the model so that the topic assignment is grounded in the topic list. \n",
    "\n",
    "![topicgpt_python](assets/img/pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "1. Make a new Python 3.9+ environment using virtualenv or conda. \n",
    "2. Install the required packages: `pip install --upgrade topicgpt_python`.\n",
    "- Our package supports OpenAI API, Google Cloud Vertex AI API, Gemini API, Azure API, and vLLM inference. vLLM requires GPUs to run. \n",
    "- Please refer to https://openai.com/pricing/ for OpenAI API pricing or to https://cloud.google.com/vertex-ai/pricing for Vertex API pricing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Run in shell\n",
    "!pip install --upgrade topicgpt_python\n",
    "\n",
    "# Needed only for the OpenAI API deployment\n",
    "export OPENAI_API_KEY={your_openai_api_key}\n",
    "\n",
    "# Needed only for the Vertex AI deployment\n",
    "export VERTEX_PROJECT={your_vertex_project}   # e.g. my-project\n",
    "export VERTEX_LOCATION={your_vertex_location} # e.g. us-central1\n",
    "\n",
    "# Needed only for Gemini deployment\n",
    "export GEMINI_API_KEY={your_gemini_api_key}\n",
    "\n",
    "# Needed only for the Azure API deployment\n",
    "export AZURE_OPENAI_API_KEY={your_azure_api_key}\n",
    "export AZURE_OPENAI_ENDPOINT={your_azure_endpoint}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "1. First, define the necessary file paths for I/O operations in `config.yml`. \n",
    "2. Then, import the necessary modules and functions from `topicgpt_python`.\n",
    "3. Store your data in `data/input` and modify the `data_sample` path in `config.yml`. \n",
    "\n",
    "- Prepare your `.jsonl` data file in the following format:\n",
    "    ```\n",
    "    {\n",
    "        \"id\": \"IDs (optional)\",\n",
    "        \"text\": \"Documents\",\n",
    "        \"label\": \"Ground-truth labels (optional)\"\n",
    "    }\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 11-10 10:22:32 _custom_ops.py:19] Failed to import from vllm._C with ModuleNotFoundError(\"No module named 'vllm._C'\")\n",
      "INFO 11-10 10:22:32 importing.py:10] Triton not installed; certain GPU-related functions will not be available.\n"
     ]
    }
   ],
   "source": [
    "from topicgpt_python import *\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Generation \n",
    "Generate high-level topics using `generate_topic_lvl1`. \n",
    "- Define the api type and model. \n",
    "- Define your seed topics in `prompt/seed_1.md`.\n",
    "- (Optional) Modify few-shot examples in `prompt/generation_1.txt`.\n",
    "- Expect the generated topics in `data/output/{data_name}/generation_1.md` and `data/output/{data_name}/generation_1.jsonl`.\n",
    "- Right now, early stopping is set to 100, meaning that if no new topic has been generated in the last 100 iterations, the generation process will stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Initializing topic generation...\n",
      "Model: gpt-4o\n",
      "Data file: data/input/sample.jsonl\n",
      "Prompt file: prompt/generation_1.txt\n",
      "Seed file: prompt/seed_1.md\n",
      "Output file: data/output/sample/generation_1.jsonl\n",
      "Topic file: data/output/sample/generation_1.md\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:02<00:11,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 610 ~$0.0030499999999999998\n",
      "Response token usage: 18 ~$0.00027\n",
      "Topics: [1] Environment: Involves the management and conservation of natural resources and ecosystems.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:04<00:06,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 1271 ~$0.0063549999999999995\n",
      "Response token usage: 24 ~$0.00036\n",
      "Topics: [1] Environment: Mentions the use of land and natural resources, including hydropower generation and land management.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:05<00:03,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 823 ~$0.004115\n",
      "Response token usage: 17 ~$0.000255\n",
      "Topics: [1] Environment: Mentions the protection and management of natural habitats and ecosystems.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:06<00:01,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 632 ~$0.0031599999999999996\n",
      "Response token usage: 14 ~$0.00021\n",
      "Topics: [1] Environment: Mentions sustainable development and environmental review processes.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:07<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 566 ~$0.00283\n",
      "Response token usage: 17 ~$0.000255\n",
      "Topics: [1] Trade: Mentions the exchange of capital, goods, and services.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<topicgpt_python.utils.TopicTree at 0x34d5dca60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_topic_lvl1(\n",
    "    \"openai\",\n",
    "    \"gpt-4o\",\n",
    "    config[\"data_sample\"],\n",
    "    config[\"generation\"][\"prompt\"],\n",
    "    config[\"generation\"][\"seed\"],\n",
    "    config[\"generation\"][\"output\"],\n",
    "    config[\"generation\"][\"topic_output\"],\n",
    "    verbose=config[\"verbose\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Refinement\n",
    "If topics are generated by a weaker model, there sometimes exist irrelevant or redundant topics. This module: \n",
    "- Merges similar topics.\n",
    "- Removes overly specific or redundant topics that occur < 1% of the time (you can skip this by setting `remove` to False in `config.yml`).\n",
    "- Expect the refined topics in `data/output/{data_name}/refinement_1.md` and `data/output/{data_name}/refinement_1.jsonl`. If nothing happens, it means that the topic list is coherent.\n",
    "- If you're unsatisfied with the refined topics, call the function again with the refined topic file and refined topic file from the previous iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Initializing topic refinement...\n",
      "Model: gpt-4o\n",
      "Input data file: data/output/sample/generation_1.jsonl\n",
      "Prompt file: prompt/refinement.txt\n",
      "Output file: data/output/sample/refinement.md\n",
      "Topic file: data/output/sample/generation_1.md\n",
      "-------------------\n",
      "No topic pairs to be merged.\n",
      "No topics removed.\n",
      "Node('/Topics', count=1, desc='Root topic', lvl=0)\n",
      "├── Node('/Topics/Environment', count=4, desc='Involves the management and conservation of natural resources and ecosystems.', lvl=1)\n",
      "└── Node('/Topics/Trade', count=1, desc='Mentions the exchange of capital, goods, and services.', lvl=1)\n"
     ]
    }
   ],
   "source": [
    "# Optional: Refine topics if needed\n",
    "if config[\"refining_topics\"]:\n",
    "    refine_topics(\n",
    "        \"openai\",\n",
    "        \"gpt-4o\",\n",
    "        config[\"refinement\"][\"prompt\"],\n",
    "        config[\"generation\"][\"output\"],\n",
    "        config[\"generation\"][\"topic_output\"],\n",
    "        config[\"refinement\"][\"topic_output\"],\n",
    "        config[\"refinement\"][\"output\"],\n",
    "        verbose=config[\"verbose\"],\n",
    "        remove=config[\"refinement\"][\"remove\"],\n",
    "        mapping_file=config[\"refinement\"][\"mapping_file\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtopic Generation \n",
    "Generate subtopics using `generate_topic_lvl2`.\n",
    "- This function iterates over each high-level topic and generates subtopics based on a few example documents associated with the high-level topic.\n",
    "- Expect the generated topics in `data/output/{data_name}/generation_2.md` and `data/output/{data_name}/generation_2.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Initializing topic generation (lvl 2)...\n",
      "Model: gpt-4o\n",
      "Data file: data/output/sample/generation_1.jsonl\n",
      "Prompt file: prompt/generation_2.txt\n",
      "Seed file: data/output/sample/generation_1.md\n",
      "Output file: data/output/sample/generation_2.jsonl\n",
      "Topic file: data/output/sample/generation_2.md\n",
      "-------------------\n",
      "Number of remaining documents for prompting: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current topic: [1] Environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:03<00:03,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtopics: [1] Environment\n",
      "   [2] Conservation (Document: 1): Focuses on the preservation and management of natural areas, such as roadless areas within national forests.\n",
      "   [2] Indigenous Rights and Compensation (Document: 2): Pertains to the rights and compensation of indigenous tribes for the use of their land, particularly in relation to hydropower projects.\n",
      "   [2] Marine Habitat Protection (Document: 3): Involves the protection and management of marine habitats, specifically related to the conversion of decommissioned oil and gas platforms into artificial reefs.\n",
      "   [2] Sustainable Transportation Development (Document: 4): Concerns the development of sustainable transportation systems, including aerotropolis projects that integrate multimodal transportation networks.\n",
      "Conservation (Count: 0): Focuses on the preservation and management of natural areas, such as roadless areas within national forests.\n",
      "Indigenous Rights and Compensation (Count: 0): Pertains to the rights and compensation of indigenous tribes for the use of their land, particularly in relation to hydropower projects.\n",
      "Marine Habitat Protection (Count: 0): Involves the protection and management of marine habitats, specifically related to the conversion of decommissioned oil and gas platforms into artificial reefs.\n",
      "Sustainable Transportation Development (Count: 0): Concerns the development of sustainable transportation systems, including aerotropolis projects that integrate multimodal transportation networks.\n",
      "--------------------------------------------------\n",
      "Current topic: [1] Trade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtopics: [1] Trade\n",
      "\n",
      "The provided document does not relate to the topic of \"Trade\" or suggest any subtopics under it. Therefore, no second-level topics are added.\n",
      "Not a match: \n",
      "Not a match: The provided document does not relate to the topic of \"Trade\" or suggest any subtopics under it. Therefore, no second-level topics are added.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Optional: Generate subtopics\n",
    "if config[\"generate_subtopics\"]:\n",
    "    generate_topic_lvl2(\n",
    "        \"openai\",\n",
    "        \"gpt-4o\",\n",
    "        config[\"generation\"][\"topic_output\"],\n",
    "        config[\"generation\"][\"output\"],\n",
    "        config[\"generation_2\"][\"prompt\"],\n",
    "        config[\"generation_2\"][\"output\"],\n",
    "        config[\"generation_2\"][\"topic_output\"],\n",
    "        verbose=config[\"verbose\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Assignment\n",
    "Assign the generated topics to the input text using `assign_topics`. Each assignment is supported by a quote from the input text.\n",
    "- Expect the assigned topics in `data/output/{data_name}/assignment.jsonl`. \n",
    "- The model used here is often a weaker model to save cost, so the topics may not be grounded in the topic list. To correct this, use the `correct_topics` module. If there are still errors/hallucinations, run the `correct_topics` module again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Initializing topic assignment...\n",
      "Model: gpt-4o-mini\n",
      "Data file: data/input/sample.jsonl\n",
      "Prompt file: prompt/assignment.txt\n",
      "Output file: data/output/sample/assignment.jsonl\n",
      "Topic file: data/output/sample/generation_1.md\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:01<00:04,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 502 ~$0.0025099999999999996\n",
      "Response token usage: 49 ~$0.000735\n",
      "Response: [1] Environment: The document discusses the management and conservation of roadless areas within the National Forest System, which directly relates to environmental conservation efforts. (\"...directs the Secretary of Agriculture to manage such Areas to maintain their roadless character.\")\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:02<00:04,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 1158 ~$0.00579\n",
      "Response token usage: 113 ~$0.001695\n",
      "Response: [1] Environment: The document discusses the use of land for hydropower generation and the management of resources related to the Spokane Tribe, which involves environmental considerations. (\"...for the use of its land for hydropower generation by the Grand Coulee Dam.\")\n",
      "\n",
      "[1] Trade: The document mentions financial transactions and compensation related to the use of resources, which can be associated with trade aspects. (\"...constitute full satisfaction of the claim of the Tribe to a fair share of the annual hydropower revenues generated by the Grand Coulee Dam project...\")\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:04<00:02,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 710 ~$0.00355\n",
      "Response token usage: 68 ~$0.00102\n",
      "Response: [1] Environment: The document discusses the assessment and management of offshore oil and gas platforms that have become critical for marine fisheries habitat, which involves the conservation of ecosystems. (\"...assess each offshore oil and gas platform in the Gulf of Mexico that is no longer useful for operations, and has become critical for a marine fisheries habitat...\")\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:06<00:01,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 519 ~$0.002595\n",
      "Response token usage: 113 ~$0.001695\n",
      "Response: [1] Environment: The document discusses the establishment of a grant program that includes activities related to environmental review, which is part of managing and conserving natural resources. (\"...assist in planning, design, environmental review, or land acquisition activities for one or more specified kinds of projects...\")\n",
      "\n",
      "[1] Trade: The document mentions the development of transportation systems that facilitate efficient and sustainable connectivity, which can be related to the exchange of goods and services. (\"...provide efficient, sustainable, and intermodal connectivity to a defined region of economic significance centered around a major airport.\")\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:07<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token usage: 453 ~$0.002265\n",
      "Response token usage: 71 ~$0.001065\n",
      "Response: [1] Trade: The document discusses the requirements for issuing driver's licenses and identification documents, which relates to the verification of lawful immigration status, impacting the exchange of services and identification in trade contexts. (\"...prohibit a state from issuing a driver's license or identification document to a person unless the state has complied with certain citizenship or lawful immigration status verification requirements.\")\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assignment\n",
    "assign_topics(\n",
    "    \"openai\",\n",
    "    \"gpt-4o-mini\",\n",
    "    config[\"data_sample\"],\n",
    "    config[\"assignment\"][\"prompt\"],\n",
    "    config[\"assignment\"][\"output\"],\n",
    "    config[\"generation\"][\n",
    "        \"topic_output\"\n",
    "    ],  # TODO: change to generation_2 if you have subtopics, or config['refinement']['topic_output'] if you refined topics\n",
    "    verbose=config[\"verbose\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Initializing topic correction...\n",
      "Model: gpt-4o-mini\n",
      "Data file: data/output/sample/assignment.jsonl\n",
      "Prompt file: prompt/correction.txt\n",
      "Output file: data/output/sample/assignment_corrected.jsonl\n",
      "Topic file: data/output/sample/generation_1.md\n",
      "-------------------\n",
      "Number of errors: 0\n",
      "Number of hallucinated topics: 0\n",
      "All topics are correct.\n"
     ]
    }
   ],
   "source": [
    "# Correction\n",
    "correct_topics(\n",
    "    \"openai\",\n",
    "    \"gpt-4o-mini\",\n",
    "    config[\"assignment\"][\"output\"],\n",
    "    config[\"correction\"][\"prompt\"],\n",
    "    config[\"generation\"][\n",
    "        \"topic_output\"\n",
    "    ],  # TODO: change to generation_2 if you have subtopics, or config['refinement']['topic_output'] if you refined topics\n",
    "    config[\"correction\"][\"output\"],\n",
    "    verbose=config[\"verbose\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topicgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
